{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä An√°lise Explorat√≥ria de Dados de da Rede Sonda üå¶Ô∏è\n",
    "\n",
    "## üìå Introdu√ß√£o\n",
    "Este notebook realiza uma an√°lise explorat√≥ria dos dados meteorol√≥gicos coletados de diversas esta√ß√µes. O objetivo √© entender a estrutura dos dados, avaliar sua qualidade e identificar padr√µes relevantes.\n",
    "\n",
    "## üìÇ Fonte dos Dados\n",
    "- Arquivos CSV formatados armazenados no ftp\n",
    "- Cont√™m medi√ß√µes de vari√°veis meteorol√≥gicas, solarim√©tricas e cameras.\n",
    "\n",
    "## üîç Objetivos da An√°lise\n",
    "1. **Carregar e explorar os dados**: verificar onde os dados est√£o armazenados, seu formato e estrutura.\n",
    "2. **Dimensionamento e vari√°veis dispon√≠veis**: entender o tamanho dos arquivos, n√∫mero de registros e colunas.\n",
    "3. **An√°lise temporal dos dados dispon√≠veis**: identificar o per√≠odo coberto e eventuais lacunas temporais.\n",
    "4. **Visualiza√ß√£o da distribui√ß√£o espacial das esta√ß√µes**: verificar a abrang√™ncia geogr√°fica das medi√ß√µes.\n",
    "5. **Explora√ß√£o inicial de distribui√ß√µes**: histogramas e estat√≠sticas b√°sicas das vari√°veis.\n",
    "6. **An√°lise de qualidade dos dados** *(√∫ltima etapa)*: identificar valores ausentes, inconsist√™ncias e flags de qualidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carregar e Explorar os Dados\n",
    "Vamos come√ßar listando o tamanho da base de dados que est√£o no diret√≥rio do ftp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diret√≥rio onde os arquivos est√£o localizados\n",
    "DIRETORIO = '/media/helvecioneto/Barracuda/sonda/novos_formatados/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/\n",
      "1,8G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/PMA\n",
      "1,7G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/PTR\n",
      "1,6G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/SMS\n",
      "1,4G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CPA\n",
      "1,2G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/BRB\n",
      "1,1G\t/media/helvecioneto/Barracuda/sonda/novos_formatados/ORN\n",
      "989M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/FLN\n",
      "848M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CGR\n",
      "837M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CTS\n",
      "759M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/JOI\n",
      "749M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/NAT\n",
      "686M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/SLZ\n",
      "547M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/MDS\n",
      "521M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/STM\n",
      "464M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/SBR\n",
      "445M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/SPK\n",
      "413M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/TMA\n",
      "391M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CMS\n",
      "365M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/MCL\n",
      "315M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CAI\n",
      "300M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/UBE\n",
      "284M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/BJL\n",
      "175M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/TLG\n",
      "171M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CTB\n",
      "55M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CBA\n",
      "39M\t/media/helvecioneto/Barracuda/sonda/novos_formatados/SJC\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/TRI\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/SCR\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/RLM\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/OPO\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/LEB\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CPN\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/CHP\n",
      "196K\t/media/helvecioneto/Barracuda/sonda/novos_formatados/BAB\n"
     ]
    }
   ],
   "source": [
    "# Exibe o tamanho de cada arquivo no diret√≥rio ordenado por tamanho de forma decrescente\n",
    "!du -h --max-depth=1 {DIRETORIO} | sort -rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 3 tipos de dados:\n",
    "- Dados Meteorol√≥gicos\n",
    "- Dados Solarim√©tricos\n",
    "- Dados Anemometricos\n",
    "\n",
    "Abaixo vamos adicionar cada tipo de dado em uma lista para facilitar a an√°lise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# listar todos os dados Meteorol√≥gicos usando o glob s√≥ para o tipo de arquivo .csv\n",
    "dados_metereologicos = glob.glob(DIRETORIO + \"*/Meteorologicos/**/*.csv\", recursive=True)\n",
    "# Remove arquivos que contenham 'YYYY_MM_MD_DQC'\n",
    "dados_metereologicos = [arquivo for arquivo in dados_metereologicos if 'YYYY_MM' not in arquivo]\n",
    "\n",
    "# listar todos os dados de Solarim√©tricos usando o glob s√≥ para o tipo de arquivo .csv\n",
    "dados_solarimetricos = glob.glob(DIRETORIO + \"*/Solarimetricos/**/*.csv\", recursive=True)\n",
    "# Remove arquivos que contenham 'YYYY_MM_MD_DQC'\n",
    "dados_solarimetricos = [arquivo for arquivo in dados_solarimetricos if 'YYYY_MM' not in arquivo]\n",
    "\n",
    "# listar todos os dados de Anemometricos usando o glob s√≥ para o tipo de arquivo .csv\n",
    "dados_anemometricos = glob.glob(DIRETORIO + \"*/Anemometricos/**/*.csv\", recursive=True)\n",
    "# Remove arquivos que contenham 'YYYY_MM_MD_DQC'\n",
    "dados_anemometricos = [arquivo for arquivo in dados_anemometricos if 'YYYY_MM' not in arquivo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de arquivos Meteorologicos: 1441\n",
      "Quantidade de arquivos Solarimetricos: 1570\n",
      "Quantidade de arquivos Anemometricos: 267\n"
     ]
    }
   ],
   "source": [
    "# Listar a quantidade de arquivos em cada categoria\n",
    "print(f\"Quantidade de arquivos Meteorologicos: {len(dados_metereologicos)}\")\n",
    "print(f\"Quantidade de arquivos Solarimetricos: {len(dados_solarimetricos)}\")\n",
    "print(f\"Quantidade de arquivos Anemometricos: {len(dados_anemometricos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos a biblioteca duckdb para realizar a an√°lise dos dados. DuckDB funciona como um banco de dados SQL, mas em mem√≥ria, o que facilita a an√°lise de grandes volumes de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar a biblioteca DuckDB para manipula√ß√£o de dados\n",
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de variaveis Solarimetricos: 38\n",
      "Numero de variaveis Meteorologicos: 13\n",
      "Numero de variaveis Anemometricos: 25\n"
     ]
    }
   ],
   "source": [
    "# Apontar o caminho das bases de dados\n",
    "ARQV_METEOROLOGICO = DIRETORIO + 'dados_meteorologicos.parquet'\n",
    "ARQV_SOLARIMETRICA = DIRETORIO + 'dados_solarimetricos.parquet'\n",
    "ARQV_ANEMOMETRICO = DIRETORIO + 'dados_anemometricos.parquet'\n",
    "\n",
    "# Nome das tabelas\n",
    "BASE_METEOROLOGICO = 'base_meteorologica'\n",
    "BASE_SOLARIMETRICA = 'base_solarimetrica'\n",
    "BASE_ANEMOMETRICO = 'base_anemometrica'\n",
    "\n",
    "# Variaveis\n",
    "SOLAR_VAR = \"acronym\",\"timestamp\",\"year\",\"day\",\"min\",\"glo_avg\",\"glo_std\",\"glo_max\",\"glo_min\",\"dif_avg\",\"dif_std\",\"dif_max\",\"dif_min\",\"par_avg\",\"par_std\",\"par_max\",\"par_min\",\"lux_avg\",\"lux_std\",\"lux_max\",\"lux_min\",\"dir_avg\",\"dir_std\",\"dir_max\",\"dir_min\",\"lw_calc_avg\",\"lw_calc_std\",\"lw_calc_max\",\"lw_calc_min\",\"lw_raw_avg\",\"lw_raw_std\",\"lw_raw_max\",\"lw_raw_min\",\"tp_glo\",\"tp_dir\",\"tp_dif\",\"tp_lw_dome\",\"tp_lw_case\"\n",
    "\n",
    "METEO_VAR = \"acronym\",\"timestamp\",\"year\",\"day\",\"min\",\"tp_sfc\",\"humid_sfc\",\"press\",\"rain\",\"ws10_avg\",\"ws10_std\",\"wd10_avg\",\"wd10_std\"\n",
    "\n",
    "ANEMO_VAR = \"acronym\",\"timestamp\",\"year\",\"day\",\"min\",\"ws10_avg\",\"ws10_std\",\"ws10_min\",\"ws10_max\",\"wd10_avg\",\"wd10_std\",\"ws25_avg\",\"ws25_std\",\"ws25_min\",\"ws25_max\",\"wd25_avg\",\"wd25_std\",\"tp_25\",\"ws50_avg\",\"ws50_std\",\"ws50_min\",\"ws50_max\",\"wd50_avg\",\"wd50_std\",\"tp_50\"\n",
    "\n",
    "print(f\"Numero de variaveis Solarimetricos: {len(SOLAR_VAR)}\")\n",
    "print(f\"Numero de variaveis Meteorologicos: {len(METEO_VAR)}\")\n",
    "print(f\"Numero de variaveis Anemometricos: {len(ANEMO_VAR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria variavel para conex√£o do banco de dados\n",
    "global con\n",
    "con = duckdb.connect(database=':memory:')\n",
    "!rm -rf .tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para criar a tabela no banco de dados e inicializa todas as vari√°veis vazias\n",
    "def criar_base(arquivo, nome_base, variaveis):\n",
    "    # Verifica se o arquivo existe, se sim carrega o arquivo\n",
    "    if os.path.exists(arquivo):\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {nome_base} AS SELECT * FROM read_csv_auto('{arquivo}')\n",
    "        \"\"\")\n",
    "    else:\n",
    "        # Criar a string com os nomes das colunas e os tipos corretos\n",
    "        columns_def = ', '.join(\n",
    "            f\"{col} VARCHAR\" if col == \"acronym\" else\n",
    "            f\"{col} TIMESTAMP\" if col == \"timestamp\" else\n",
    "            f\"{col} INT\" if col in [\"year\", \"day\", \"min\"] else\n",
    "            f\"{col} FLOAT\" \n",
    "            for col in variaveis        )\n",
    "        \n",
    "        # Criar a tabela\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {nome_base} ({columns_def})\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a base de dados meteorol√≥gicos\n",
    "criar_base(ARQV_METEOROLOGICO, BASE_METEOROLOGICO, METEO_VAR)\n",
    "# Criar a base de dados solarim√©tricos\n",
    "criar_base(ARQV_SOLARIMETRICA, BASE_SOLARIMETRICA, SOLAR_VAR)\n",
    "# Criar a base de dados anemom√©tricos\n",
    "criar_base(BASE_ANEMOMETRICO, BASE_ANEMOMETRICO, ANEMO_VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronym</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>min</th>\n",
       "      <th>tp_sfc</th>\n",
       "      <th>humid_sfc</th>\n",
       "      <th>press</th>\n",
       "      <th>rain</th>\n",
       "      <th>ws10_avg</th>\n",
       "      <th>ws10_std</th>\n",
       "      <th>wd10_avg</th>\n",
       "      <th>wd10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>22.379999</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>1010.283997</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5.2698</td>\n",
       "      <td>0.923294</td>\n",
       "      <td>23.422167</td>\n",
       "      <td>4.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:10:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>21.219999</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.502991</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.6318</td>\n",
       "      <td>0.352908</td>\n",
       "      <td>29.199734</td>\n",
       "      <td>1.963143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:20:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.476013</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.9738</td>\n",
       "      <td>0.713510</td>\n",
       "      <td>33.528019</td>\n",
       "      <td>2.825004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:30:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.473999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.1440</td>\n",
       "      <td>0.646525</td>\n",
       "      <td>22.548946</td>\n",
       "      <td>3.690781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:40:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.629028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.440114</td>\n",
       "      <td>58.076206</td>\n",
       "      <td>8.977480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acronym           timestamp  year  day  min     tp_sfc   humid_sfc  \\\n",
       "0     FLN 2019-03-01 00:00:00  2019   60    0  22.379999   97.699997   \n",
       "1     FLN 2019-03-01 00:10:00  2019   60   10  21.219999  101.099998   \n",
       "2     FLN 2019-03-01 00:20:00  2019   60   20  21.150000  101.099998   \n",
       "3     FLN 2019-03-01 00:30:00  2019   60   30  21.080000  101.099998   \n",
       "4     FLN 2019-03-01 00:40:00  2019   60   40  21.200001  101.099998   \n",
       "\n",
       "         press  rain  ws10_avg  ws10_std   wd10_avg  wd10_std  \n",
       "0  1010.283997  0.72    5.2698  0.923294  23.422167  4.079195  \n",
       "1  1010.502991  0.00    4.6318  0.352908  29.199734  1.963143  \n",
       "2  1010.476013  0.18    3.9738  0.713510  33.528019  2.825004  \n",
       "3  1010.473999  0.00    3.1440  0.646525  22.548946  3.690781  \n",
       "4  1010.629028  0.00    0.8769  0.440114  58.076206  8.977480  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronym</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>min</th>\n",
       "      <th>glo_avg</th>\n",
       "      <th>glo_std</th>\n",
       "      <th>glo_max</th>\n",
       "      <th>glo_min</th>\n",
       "      <th>dif_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>lw_calc_min</th>\n",
       "      <th>lw_raw_avg</th>\n",
       "      <th>lw_raw_std</th>\n",
       "      <th>lw_raw_max</th>\n",
       "      <th>lw_raw_min</th>\n",
       "      <th>tp_glo</th>\n",
       "      <th>tp_dir</th>\n",
       "      <th>tp_dif</th>\n",
       "      <th>tp_lw_dome</th>\n",
       "      <th>tp_lw_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acronym, timestamp, year, day, min, glo_avg, glo_std, glo_max, glo_min, dif_avg, dif_std, dif_max, dif_min, par_avg, par_std, par_max, par_min, lux_avg, lux_std, lux_max, lux_min, dir_avg, dir_std, dir_max, dir_min, lw_calc_avg, lw_calc_std, lw_calc_max, lw_calc_min, lw_raw_avg, lw_raw_std, lw_raw_max, lw_raw_min, tp_glo, tp_dir, tp_dif, tp_lw_dome, tp_lw_case]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronym</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>min</th>\n",
       "      <th>ws10_avg</th>\n",
       "      <th>ws10_std</th>\n",
       "      <th>ws10_min</th>\n",
       "      <th>ws10_max</th>\n",
       "      <th>wd10_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>wd25_avg</th>\n",
       "      <th>wd25_std</th>\n",
       "      <th>tp_25</th>\n",
       "      <th>ws50_avg</th>\n",
       "      <th>ws50_std</th>\n",
       "      <th>ws50_min</th>\n",
       "      <th>ws50_max</th>\n",
       "      <th>wd50_avg</th>\n",
       "      <th>wd50_std</th>\n",
       "      <th>tp_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acronym, timestamp, year, day, min, ws10_avg, ws10_std, ws10_min, ws10_max, wd10_avg, wd10_std, ws25_avg, ws25_std, ws25_min, ws25_max, wd25_avg, wd25_std, tp_25, ws50_avg, ws50_std, ws50_min, ws50_max, wd50_avg, wd50_std, tp_50]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verifica o conteudo da tabela base_meteorologica\n",
    "display(con.execute(f\"SELECT * FROM {BASE_METEOROLOGICO} LIMIT 5\").fetch_df())\n",
    "# Verifica o conteudo da tabela base_solarimetrica\n",
    "display(con.execute(f\"SELECT * FROM {BASE_SOLARIMETRICA} LIMIT 5\").fetch_df())\n",
    "# Verifica o conteudo da tabela base_anemometrica\n",
    "display(con.execute(f\"SELECT * FROM {BASE_ANEMOMETRICO} LIMIT 5\").fetch_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inseridos 4464 registros na base base_meteorologica para esta√ß√£o FLN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronym</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>min</th>\n",
       "      <th>tp_sfc</th>\n",
       "      <th>humid_sfc</th>\n",
       "      <th>press</th>\n",
       "      <th>rain</th>\n",
       "      <th>ws10_avg</th>\n",
       "      <th>ws10_std</th>\n",
       "      <th>wd10_avg</th>\n",
       "      <th>wd10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>22.379999</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>1010.283997</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5.2698</td>\n",
       "      <td>0.923294</td>\n",
       "      <td>23.422167</td>\n",
       "      <td>4.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:10:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>21.219999</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.502991</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.6318</td>\n",
       "      <td>0.352908</td>\n",
       "      <td>29.199734</td>\n",
       "      <td>1.963143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:20:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.476013</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.9738</td>\n",
       "      <td>0.713510</td>\n",
       "      <td>33.528019</td>\n",
       "      <td>2.825004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:30:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.473999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.1440</td>\n",
       "      <td>0.646525</td>\n",
       "      <td>22.548946</td>\n",
       "      <td>3.690781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:40:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.629028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.440114</td>\n",
       "      <td>58.076206</td>\n",
       "      <td>8.977480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:10:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1390</td>\n",
       "      <td>28.110001</td>\n",
       "      <td>72.300003</td>\n",
       "      <td>1008.625000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2127</td>\n",
       "      <td>0.588603</td>\n",
       "      <td>70.239052</td>\n",
       "      <td>4.574341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:20:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1400</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>70.430000</td>\n",
       "      <td>1008.927979</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2316</td>\n",
       "      <td>0.752738</td>\n",
       "      <td>277.135406</td>\n",
       "      <td>7.986555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:30:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1410</td>\n",
       "      <td>28.530001</td>\n",
       "      <td>74.720001</td>\n",
       "      <td>1008.989014</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.358513</td>\n",
       "      <td>9.854651</td>\n",
       "      <td>6.379753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:40:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1420</td>\n",
       "      <td>28.469999</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>1008.833008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.1380</td>\n",
       "      <td>0.227866</td>\n",
       "      <td>39.093452</td>\n",
       "      <td>3.959011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:50:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1430</td>\n",
       "      <td>28.540001</td>\n",
       "      <td>72.930000</td>\n",
       "      <td>1008.866028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.1087</td>\n",
       "      <td>0.663975</td>\n",
       "      <td>50.867542</td>\n",
       "      <td>5.695300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8928 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acronym           timestamp  year  day   min     tp_sfc   humid_sfc  \\\n",
       "0        FLN 2019-03-01 00:00:00  2019   60     0  22.379999   97.699997   \n",
       "1        FLN 2019-03-01 00:10:00  2019   60    10  21.219999  101.099998   \n",
       "2        FLN 2019-03-01 00:20:00  2019   60    20  21.150000  101.099998   \n",
       "3        FLN 2019-03-01 00:30:00  2019   60    30  21.080000  101.099998   \n",
       "4        FLN 2019-03-01 00:40:00  2019   60    40  21.200001  101.099998   \n",
       "...      ...                 ...   ...  ...   ...        ...         ...   \n",
       "8923     FLN 2019-01-31 23:10:00  2019   31  1390  28.110001   72.300003   \n",
       "8924     FLN 2019-01-31 23:20:00  2019   31  1400  28.620001   70.430000   \n",
       "8925     FLN 2019-01-31 23:30:00  2019   31  1410  28.530001   74.720001   \n",
       "8926     FLN 2019-01-31 23:40:00  2019   31  1420  28.469999   72.250000   \n",
       "8927     FLN 2019-01-31 23:50:00  2019   31  1430  28.540001   72.930000   \n",
       "\n",
       "            press  rain  ws10_avg  ws10_std    wd10_avg  wd10_std  \n",
       "0     1010.283997  0.72    5.2698  0.923294   23.422167  4.079195  \n",
       "1     1010.502991  0.00    4.6318  0.352908   29.199734  1.963143  \n",
       "2     1010.476013  0.18    3.9738  0.713510   33.528019  2.825004  \n",
       "3     1010.473999  0.00    3.1440  0.646525   22.548946  3.690781  \n",
       "4     1010.629028  0.00    0.8769  0.440114   58.076206  8.977480  \n",
       "...           ...   ...       ...       ...         ...       ...  \n",
       "8923  1008.625000  0.00    1.2127  0.588603   70.239052  4.574341  \n",
       "8924  1008.927979  0.00    1.2316  0.752738  277.135406  7.986555  \n",
       "8925  1008.989014  0.00    0.6841  0.358513    9.854651  6.379753  \n",
       "8926  1008.833008  0.00    1.1380  0.227866   39.093452  3.959011  \n",
       "8927  1008.866028  0.00    1.1087  0.663975   50.867542  5.695300  \n",
       "\n",
       "[8928 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fun√ß√£o para popular a tabela com os dados, nessa fun√ß√£o ser√° poss√≠vel fazer o append dos dados, atualizar os dados variavel a variavel\n",
    "def popular_base(args):\n",
    "    arquivo, base, linha_linha, var_var, sobreescrever = args\n",
    "\n",
    "    # Le o arquivo CSV e insere os dados na tabela correspondente\n",
    "    try:\n",
    "        # Lendo os dados do CSV, pulando a segunda linha que cont√©m informa√ß√µes extras\n",
    "        new_data = pd.read_csv(arquivo, skiprows=[1])\n",
    "        \n",
    "        # Coluna de vari√°veis (todas as colunas ap√≥s as primeiras 5 que s√£o metadados)\n",
    "        variaveis = new_data.columns[5:]\n",
    "        \n",
    "        # Limpeza de dados: substituir v√≠rgulas por pontos em dados num√©ricos\n",
    "        new_data[variaveis] = new_data[variaveis].replace({',': '.'}, regex=True)\n",
    "        \n",
    "        # Substituir valores como \"xxx-\" por 0 (dados inv√°lidos)\n",
    "        new_data[variaveis] = new_data[variaveis].replace({r'\\d+-': '0'}, regex=True)\n",
    "        \n",
    "        # Converter todos os dados para num√©rico quando poss√≠vel\n",
    "        new_data[variaveis] = new_data[variaveis].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Formatar corretamente o timestamp\n",
    "        new_data['timestamp'] = pd.to_datetime(new_data['timestamp'], errors='coerce')\n",
    "        \n",
    "        # Verificar se h√° dados inv√°lidos na coluna timestamp\n",
    "        invalid_timestamps = new_data['timestamp'].isna().sum()\n",
    "        if invalid_timestamps > 0:\n",
    "            print(f\"Aviso: {invalid_timestamps} timestamps inv√°lidos encontrados no arquivo {arquivo}\")\n",
    "        \n",
    "        # Verificar se o acronimo √© v√°lido\n",
    "        if 'acronym' not in new_data.columns or new_data['acronym'].isna().all():\n",
    "            print(f\"Erro: Arquivo {arquivo} n√£o possui informa√ß√£o de esta√ß√£o (acronym)\")\n",
    "            return\n",
    "            \n",
    "        estacao = new_data['acronym'].iloc[0]\n",
    "        \n",
    "        # Pega o intervalo de tempo do arquivo\n",
    "        tempo = (new_data['timestamp'].min(), new_data['timestamp'].max())\n",
    "        \n",
    "        # Registra o DataFrame no DuckDB para opera√ß√µes\n",
    "        con.register('new_data', new_data)\n",
    "        \n",
    "        # Se for para sobreescrever, exclui os dados existentes\n",
    "        if sobreescrever:\n",
    "            con.execute(f\"DELETE FROM {base} WHERE acronym = '{estacao}' AND timestamp BETWEEN '{tempo[0]}' AND '{tempo[1]}'\")\n",
    "        \n",
    "        # Inser√ß√£o linha a linha e vari√°vel a vari√°vel (modo mais detalhado)\n",
    "        if linha_linha:\n",
    "            for i in range(len(new_data)):\n",
    "                row = new_data.iloc[i]\n",
    "                \n",
    "                # Modo vari√°vel a vari√°vel\n",
    "                if var_var:\n",
    "                    for v in variaveis:\n",
    "                        # Verifica se o registro j√° existe na base\n",
    "                        if not sobreescrever:\n",
    "                            exists = con.execute(\n",
    "                                f\"SELECT COUNT(*) FROM {base} WHERE acronym = '{estacao}' AND timestamp = '{row['timestamp']}' AND {v} = {row[v]}\"\n",
    "                            ).fetchone()[0]\n",
    "                            \n",
    "                            if exists > 0:\n",
    "                                continue\n",
    "                                \n",
    "                        # Inser√ß√£o de dados vari√°vel por vari√°vel\n",
    "                        try:\n",
    "                            con.execute(\n",
    "                                f\"INSERT INTO {base} (acronym, timestamp, year, day, min, {v}) VALUES ('{estacao}', '{row['timestamp']}', {row['year']}, {row['day']}, {row['min']}, {row[v]})\"\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            print(f\"Erro ao inserir vari√°vel {v} na base {base}: {e}\")\n",
    "                else:\n",
    "                    # Verifica se o registro linha a linha j√° existe\n",
    "                    if not sobreescrever:\n",
    "                        exists = con.execute(\n",
    "                            f\"SELECT COUNT(*) FROM {base} WHERE acronym = '{estacao}' AND timestamp = '{row['timestamp']}'\"\n",
    "                        ).fetchone()[0]\n",
    "                        \n",
    "                        if exists > 0:\n",
    "                            continue\n",
    "                            \n",
    "                    # Inser√ß√£o de dados linha a linha\n",
    "                    try:\n",
    "                        con.execute(f\"INSERT INTO {base} SELECT * FROM new_data WHERE timestamp = '{row['timestamp']}'\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao inserir linha na base {base}: {e}\")\n",
    "        else:\n",
    "            # Verifica√ß√£o de dados existentes para inser√ß√£o em lote\n",
    "            if not sobreescrever:\n",
    "                count = con.execute(\n",
    "                    f\"SELECT COUNT(*) FROM {base} WHERE acronym = '{estacao}' AND timestamp BETWEEN '{tempo[0]}' AND '{tempo[1]}'\"\n",
    "                ).fetchone()[0]\n",
    "                \n",
    "                if count > 0:\n",
    "                    print(f\"Dados j√° existem para esta√ß√£o {estacao} no per√≠odo {tempo[0]} a {tempo[1]}. Use sobreescrever=True para substituir.\")\n",
    "                    return\n",
    "            \n",
    "            # Inserir todos os dados de uma vez\n",
    "            try:\n",
    "                con.execute(f\"INSERT INTO {base} SELECT * FROM new_data\")\n",
    "                print(f\"Inseridos {len(new_data)} registros na base {base} para esta√ß√£o {estacao}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao inserir dados na base {base} do arquivo {arquivo}: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar arquivo {arquivo}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronym</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>min</th>\n",
       "      <th>tp_sfc</th>\n",
       "      <th>humid_sfc</th>\n",
       "      <th>press</th>\n",
       "      <th>rain</th>\n",
       "      <th>ws10_avg</th>\n",
       "      <th>ws10_std</th>\n",
       "      <th>wd10_avg</th>\n",
       "      <th>wd10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>22.379999</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>1010.283997</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5.2698</td>\n",
       "      <td>0.923294</td>\n",
       "      <td>23.422167</td>\n",
       "      <td>4.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:10:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>21.219999</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.502991</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.6318</td>\n",
       "      <td>0.352908</td>\n",
       "      <td>29.199734</td>\n",
       "      <td>1.963143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:20:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.476013</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.9738</td>\n",
       "      <td>0.713510</td>\n",
       "      <td>33.528019</td>\n",
       "      <td>2.825004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:30:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.473999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.1440</td>\n",
       "      <td>0.646525</td>\n",
       "      <td>22.548946</td>\n",
       "      <td>3.690781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-03-01 00:40:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>1010.629028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.440114</td>\n",
       "      <td>58.076206</td>\n",
       "      <td>8.977480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:10:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1390</td>\n",
       "      <td>28.110001</td>\n",
       "      <td>72.300003</td>\n",
       "      <td>1008.625000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2127</td>\n",
       "      <td>0.588603</td>\n",
       "      <td>70.239052</td>\n",
       "      <td>4.574341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:20:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1400</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>70.430000</td>\n",
       "      <td>1008.927979</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2316</td>\n",
       "      <td>0.752738</td>\n",
       "      <td>277.135406</td>\n",
       "      <td>7.986555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:30:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1410</td>\n",
       "      <td>28.530001</td>\n",
       "      <td>74.720001</td>\n",
       "      <td>1008.989014</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.358513</td>\n",
       "      <td>9.854651</td>\n",
       "      <td>6.379753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:40:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1420</td>\n",
       "      <td>28.469999</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>1008.833008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.1380</td>\n",
       "      <td>0.227866</td>\n",
       "      <td>39.093452</td>\n",
       "      <td>3.959011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>FLN</td>\n",
       "      <td>2019-01-31 23:50:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1430</td>\n",
       "      <td>28.540001</td>\n",
       "      <td>72.930000</td>\n",
       "      <td>1008.866028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.1087</td>\n",
       "      <td>0.663975</td>\n",
       "      <td>50.867542</td>\n",
       "      <td>5.695300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8928 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acronym           timestamp  year  day   min     tp_sfc   humid_sfc  \\\n",
       "0        FLN 2019-03-01 00:00:00  2019   60     0  22.379999   97.699997   \n",
       "1        FLN 2019-03-01 00:10:00  2019   60    10  21.219999  101.099998   \n",
       "2        FLN 2019-03-01 00:20:00  2019   60    20  21.150000  101.099998   \n",
       "3        FLN 2019-03-01 00:30:00  2019   60    30  21.080000  101.099998   \n",
       "4        FLN 2019-03-01 00:40:00  2019   60    40  21.200001  101.099998   \n",
       "...      ...                 ...   ...  ...   ...        ...         ...   \n",
       "8923     FLN 2019-01-31 23:10:00  2019   31  1390  28.110001   72.300003   \n",
       "8924     FLN 2019-01-31 23:20:00  2019   31  1400  28.620001   70.430000   \n",
       "8925     FLN 2019-01-31 23:30:00  2019   31  1410  28.530001   74.720001   \n",
       "8926     FLN 2019-01-31 23:40:00  2019   31  1420  28.469999   72.250000   \n",
       "8927     FLN 2019-01-31 23:50:00  2019   31  1430  28.540001   72.930000   \n",
       "\n",
       "            press  rain  ws10_avg  ws10_std    wd10_avg  wd10_std  \n",
       "0     1010.283997  0.72    5.2698  0.923294   23.422167  4.079195  \n",
       "1     1010.502991  0.00    4.6318  0.352908   29.199734  1.963143  \n",
       "2     1010.476013  0.18    3.9738  0.713510   33.528019  2.825004  \n",
       "3     1010.473999  0.00    3.1440  0.646525   22.548946  3.690781  \n",
       "4     1010.629028  0.00    0.8769  0.440114   58.076206  8.977480  \n",
       "...           ...   ...       ...       ...         ...       ...  \n",
       "8923  1008.625000  0.00    1.2127  0.588603   70.239052  4.574341  \n",
       "8924  1008.927979  0.00    1.2316  0.752738  277.135406  7.986555  \n",
       "8925  1008.989014  0.00    0.6841  0.358513    9.854651  6.379753  \n",
       "8926  1008.833008  0.00    1.1380  0.227866   39.093452  3.959011  \n",
       "8927  1008.866028  0.00    1.1087  0.663975   50.867542  5.695300  \n",
       "\n",
       "[8928 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(con.execute(f\"SELECT * FROM {BASE_METEOROLOGICO}\").fetch_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para popular a base de dados\n",
    "def inserir_dados(args):\n",
    "    # Recebe os argumentos\n",
    "    base, arquivo, linha_linha = args\n",
    "    # Lendo os novos dados do CSV, pulando a segunda linha mas mantendo o cabe√ßalho\n",
    "    new_data = pd.read_csv(arquivo, skiprows=[1])\n",
    "    # Coluna de vari√°veis\n",
    "    variaveis = new_data.columns[5:]\n",
    "    # Caso alguma vari√°vel contenha \",\" substitui por \".\" em seus valores\n",
    "    new_data[variaveis] = new_data[variaveis].replace({',': '.'}, regex=True)\n",
    "    # Caso alguma vari√°vel conhenha um numero segido de um - substitui por 0\n",
    "    new_data[variaveis] = new_data[variaveis].replace({r'\\d+-': '0'}, regex=True)\n",
    "    # Formata os dados for√ßando para que sejam n√∫mericos, e caso n√£o seja, substitui pelo valor original\n",
    "    new_data = new_data.apply(pd.to_numeric, errors='coerce').fillna(new_data)\n",
    "    # Converte a coluna de timestamp para datetime\n",
    "    new_data['timestamp'] = pd.to_datetime(new_data['timestamp'], errors='coerce')\n",
    "    # Pega o nome da esta√ß√£o do arquivo\n",
    "    estacao = new_data['acronym'][0]\n",
    "    # Pega o tempo m√≠nimo e m√°ximo\n",
    "    tempo = new_data['timestamp'].min(), new_data['timestamp'].max()\n",
    "    # Registra o DataFrame new_data na tabela base\n",
    "    con.register('new_data', new_data)\n",
    "    # Verifica se √© linha a linha\n",
    "    if linha_linha:\n",
    "       # Verifica linha a linha e vari√°vel a vari√°vel se j√° existe na base\n",
    "        for i in range(new_data.shape[0]):\n",
    "            for v in variaveis:\n",
    "                if con.execute(f\"SELECT COUNT(*) FROM {base} WHERE acronym = '{estacao}' AND timestamp = '{new_data['timestamp'][i]}' AND {v} = {new_data[v][i]};\").fetch_df().values[0][0] == 0:\n",
    "                    try:\n",
    "                        con.execute(f\"INSERT INTO {base} SELECT * FROM new_data WHERE acronym = '{estacao}' AND timestamp = '{new_data['timestamp'][i]}' AND {v} = {new_data[v][i]};\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao inserir dados da vari√°vel {v} na base {base} do arquivo {arquivo}\")\n",
    "                        print(e)\n",
    "    else: # Insere todos os dados de uma vez\n",
    "         # Verifica se dados j√° existem\n",
    "        if con.execute(f\"SELECT COUNT(*) FROM {base} WHERE acronym = '{estacao}' AND timestamp BETWEEN '{tempo[0]}' AND '{tempo[1]}';\").fetch_df().values[0][0] > 0:\n",
    "            return\n",
    "        try:\n",
    "            con.execute(f\"INSERT INTO {base} SELECT * FROM new_data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao inserir dados na base {base} do arquivo {arquivo}\")\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes para inserir dados de forma paralela ou sequencial\n",
    "def inserir_dados_paralelo(base, arquivos, linha_linha=False):\n",
    "    print(f\"Inserindo dados na base {base} de forma paralela\")\n",
    "    with Pool() as pool:\n",
    "        pool.map(inserir_dados, [(base, arquivo, linha_linha) for arquivo in arquivos])\n",
    "        \n",
    "# Fun√ß√£o para inserir os dados de forma sequencial\n",
    "def inserir_dados_sequencial(base, arquivos, linha_linha=False):\n",
    "    print(f\"Inserindo dados na base {base} de forma sequencial\")\n",
    "    for arquivo in arquivos:\n",
    "        inserir_dados((base, arquivo, linha_linha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popula a base de dados meteorol√≥gicos\n",
    "inserir_dados_sequencial(BASE_METEOROLOGICO, dados_metereologicos, linha_linha=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserindo dados na base base_solarimetrica de forma sequencial\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_08_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_06_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_01_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_12_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_02_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_03_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_11_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_09_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_04_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_07_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_10_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2021/ORN_2021_05_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_04_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_10_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_11_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_12_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_06_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_05_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_07_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_09_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2020/ORN_2020_08_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_10_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_11_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_05_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_08_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_12_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_06_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_09_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_03_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_04_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_01_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_07_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2024/ORN_2024_02_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_05_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_08_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_01_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_12_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_07_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_10_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_09_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_02_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_04_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_03_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_11_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2023/ORN_2023_06_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2025/ORN_2025_04_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2025/ORN_2025_02_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2025/ORN_2025_03_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n",
      "Erro ao inserir dados na base base_solarimetrica do arquivo /media/helvecioneto/Barracuda/sonda/novos_formatados/ORN/Solarimetricos/2025/ORN_2025_01_SD_formatado.csv\n",
      "Binder Error: table base_solarimetrica has 34 columns but 38 values were supplied\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Popula a base de dados solarim√©tricos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43minserir_dados_sequencial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_SOLARIMETRICA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdados_solarimetricos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinha_linha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36minserir_dados_sequencial\u001b[0;34m(base, arquivos, linha_linha)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserindo dados na base \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m de forma sequencial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arquivo \u001b[38;5;129;01min\u001b[39;00m arquivos:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43minserir_dados\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marquivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinha_linha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m, in \u001b[0;36minserir_dados\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      4\u001b[0m base, arquivo, linha_linha \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Lendo os novos dados do CSV, pulando a segunda linha mas mantendo o cabe√ßalho\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43marquivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Coluna de vari√°veis\u001b[39;00m\n\u001b[1;32m      8\u001b[0m variaveis \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m5\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:376\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    374\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m union_categoricals(arrs, sort_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_cat_dtypes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result[name]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    378\u001b[0m         warning_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(name))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/dtypes/concat.py:78\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     77\u001b[0m     to_concat_arrs \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[np.ndarray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_arrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Popula a base de dados solarim√©tricos\n",
    "inserir_dados_sequencial(BASE_SOLARIMETRICA, dados_solarimetricos, linha_linha=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popula a base de dados anemom√©tricos\n",
    "inserir_dados_sequencial(BASE_ANEMOMETRICO, dados_anemometricos, linha_linha=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar a base de dados meteorol√≥gicos em um arquivo parquet caso n√£o exista\n",
    "if not os.path.exists(ARQV_METEOROLOGICO):\n",
    "    con.execute(f\"COPY {BASE_METEOROLOGICO} TO '{ARQV_METEOROLOGICO}' (FORMAT 'parquet')\")\n",
    "# Salvar a base de dados solarim√©tricos em um arquivo parquet caso n√£o exista\n",
    "if not os.path.exists(ARQV_SOLARIMETRICA):\n",
    "    con.execute(f\"COPY {BASE_SOLARIMETRICA} TO '{ARQV_SOLARIMETRICA}' (FORMAT 'parquet')\")\n",
    "# Salvar a base de dados anemom√©tricos em um arquivo parquet caso n√£o exista\n",
    "if not os.path.exists(ARQV_ANEMOMETRICO):\n",
    "    con.execute(f\"COPY {BASE_ANEMOMETRICO} TO '{ARQV_ANEMOMETRICO}' (FORMAT 'parquet')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as bases de dados criadas e carregadas em mem√≥ria, podemos come√ßar a an√°lise explorat√≥ria dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica o conteudo da tabela base_meteorologica\n",
    "con.execute(f\"SELECT * FROM {BASE_METEOROLOGICO} LIMIT 5\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica o conteudo da tabela base_solarimetrica\n",
    "con.execute(f\"SELECT * FROM {BASE_SOLARIMETRICA} LIMIT 5\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega apenas colunas de dados meteorol√≥gicos\n",
    "colunas_meteoro = con.execute(f\"SELECT * FROM {BASE_METEOROLOGICO} LIMIT 1\").description\n",
    "colunas_meteoro = [c[0] for c in colunas_meteoro[5:]]\n",
    "print(f\"Colunas de dados meteorol√≥gicos: {colunas_meteoro}\")\n",
    "\n",
    "# Pega apenas colunas de dados solarim√©tricos\n",
    "colunas_solar = con.execute(f\"SELECT * FROM {BASE_SOLARIMETRICA} LIMIT 1\").description\n",
    "colunas_solar = [c[0] for c in colunas_solar[5:]]\n",
    "print(f\"Colunas de dados solarim√©tricos: {colunas_solar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira an√°lise ser√° a verifica√ß√£o temporal dos dados, para entender o per√≠odo coberto e eventuais lacunas temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_temporal(base):\n",
    "    # Faz um agrupamento por acronym e timestamp para verificar se os dados s√£o temporais, fazendo a contagem de registros por dia\n",
    "    query = f\"\"\"\n",
    "    SELECT acronym, DATE_TRUNC('month', timestamp) AS data, COUNT(*) AS registros\n",
    "    FROM {base}\n",
    "    GROUP BY acronym, data\n",
    "    ORDER BY data\n",
    "    \"\"\"\n",
    "    return con.execute(query).fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se os dados meteorol√≥gicos s√£o temporais\n",
    "verifica_temporal(BASE_METEOROLOGICO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_dados_invalidos(base, colunas): \n",
    "    query = f\"\"\"\n",
    "    SELECT acronym, COUNT(*) AS total_dados,\n",
    "    \"\"\"\n",
    "    # Para cada coluna em colunas_meteoro, criamos a parte do \"dados_invalidos\"\n",
    "    for i, coluna in enumerate(colunas):\n",
    "        query += f\"\"\"\n",
    "        SUM(CASE WHEN \\\"{coluna}\\\" = 3333.0 THEN 1 ELSE 0 END) AS {coluna}_3333,\n",
    "        SUM(CASE WHEN \\\"{coluna}\\\" = -5555.0 THEN 1 ELSE 0 END) AS {coluna}_minus_5555,\n",
    "        \"\"\"\n",
    "    # Remover a √∫ltima v√≠rgula da consulta\n",
    "    query = query.rstrip(\",\\n\")\n",
    "    # Adiciona a parte do FROM e GROUP BY\n",
    "    query += f\"\"\"\n",
    "    FROM \\\"{base}\\\"\n",
    "    GROUP BY acronym\n",
    "    \"\"\"\n",
    "    # Executar a query\n",
    "    df = con.execute(query).fetch_df()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificar_dados_invalidos(BASE_METEOROLOGICO, colunas_meteoro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificar_dados_invalidos(BASE_SOLARIMETRICA, colunas_solar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
